# WebCrawler
![WebCrawler Screenshot](https://raw.githubusercontent.com/Duallight/WebCrawler/master/Screenshots/webCrawlerExample.png)

This webcrawler starts at a given URL, and finds all links and related data, and outputs it into a text file. You can set how many worker threads available to search, as well as a depth of the search or a time limit. It automatically keeps track of elapsed time and parsed pages. 
